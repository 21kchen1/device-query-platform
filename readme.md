# 公共设施查询系统

​	本项目为小组一级项目所得到的最终结果。小组成员为：陈锴（组长），陈灿涛，陈癸伸。以下为本项目的技术文档，文档编写由组长完成。



## 引言 

### 1.1 项目背景 

​	本项目名为公共设施查询系统，主要目标在于：解决本校内公共设施信息查询的不便，服务范围包括全校区。

​	项目背景的核心问题在于：校园内现有公共设施种类繁多，且对应的管理查询小程序也分属于不同的管理公司。此现象导致用户在使用不同设施时，需要分别打开不同的小程序以获取对应的信息，反复产生登录、定位、扫码等繁琐操作。这些问题导致用户在实际使用公共设施时有着较差的体验。

​	小组成员作为校园公共设施的实际使用用户之一，由于公共设施使用频繁，深深感受到了其中的不便。并且由于公共设施面向全校，小组成员也收到了其他学生对于公共设施信息查询的不便的抱怨。总之，此问题具有广泛性与必要性，具有解决和优化的价值。

​	基于以上背景，小组成员决定基于爬虫与相关技术构建公共设施查询系统，将校内公告设施信息进行统一，以此优化校内公共设施的使用体验。

​	整个项目计划在大一完成整个系统所需的技术栈学习。在大二完成整个系统程序代码的编写、调试与优化。最终实现公共设施信息的统一查询功能。主要的任务分配为：组长负责整个系统的绝大部分开发，包括爬虫、数据库、后端与前端部分的开发，剩余成员负责对成品进行优化。

### 1.2 项目目标 

​	项目的核心目的在于统一校内公共设施信息，为用户提供便捷的使用体验。涉及的主要功能包括：公共设施、校园 OA 公告等信息的查询功能，同时基于已有信息与用户信息提供个性化信息推荐功能。系统拥有统一化、自动化、模糊化、个性化等特性，可为用户带来优质的使用体验。

​	本项目面向全校所有需要使用公共设施的人员，具有广泛的潜在用户对象，为项目提供了必要的用户产品需求。同时，由于公共设施使用的频繁性与必要性，并且项目用户的低流动性，可以为项目实际部署后提供长期且数量可观的活跃用户，为项目提供了长期运行和维护的支持。总之，本项目拥有充足而长期的用户需求。

### 1.3 文档目的 

​	本项目技术文档的目的在于：对项目背景与目标进行简单介绍。对系统、数据模型、技术栈、模块与性能优化进行具体介绍。对常见问题与参考资料进行统一说明。通过这样的说明让项目外人员可以快速理解项目。



## 系统概述 

### 2.1 系统架构 

​	本系统架构为分层架构，使用该架构在本次项目中有以下优点

* 在进行开发时，不同部分的程序可以较为独立的开发，开发成员可以只关注整个结构中的其中某一层。

* 在进行开发时可以很容易的用新的实现来替换原有层次的实现，可以提升系统的可维护性与拓展性。
* 可以降低层与层之间的依赖，提升项目各个部分的逻辑独立性。
* 有利于标准化，统一代码，提升代码可读性。
* 利于各层逻辑的复用。

​	以下为本系统架构图：

![image-20230710224311301](.assets/image-20230710224311301.png)

​	以下为本系统数据流示意图：

![image-20230711141502412](.assets/image-20230711141502412.png)

​	本系统代码基于面向对象思想编写，各类、各模块之间逻辑独立性较高。具有较高的可拓展性与可维护性。

### 2.2 功能模块 

​	本系统共分为四大模块，以下为简要介绍：

* 爬虫模块：
  * 输入：无输入，完全自动化操作。
  * 输出：公共设施信息数据，爬取异常报错。
  * 模块关联：将爬取数据注入数据库模块。
* 数据库模块：
  * 输入：爬虫模块输入数据
  * 输出：后端所需数据
  * 模块关联：存储与维护爬虫模块爬取的数据。根据后端模块需求获取输出对应数据
* 后端模块：
  * 输入：接收前端传输需求
  * 输出：处理数据库输出数据，将其特定结构向前端传输
  * 模块关联：接收前端模块需求信息。构建数据库模块查询语句。处理数据库模块返回数据。将处理数据传输回前端模块
* 前端模块：
  * 输入：用户需求，用户操作
  * 输出：用户需求对应数据，用户操作反馈
  * 模块关联：向后端模块传输用户需求。展示后端模块返回的数据。

### 2.3 硬件和软件需求 

​	为使得系统可在用户设备流畅运行，以下为本系统的硬件和软件需求：

* 硬件要求：本系统核心性能消耗位于爬虫爬取信息、数据库数据检索与后端数据处理，对硬件性能要求较低。当前市面上的绝大多数终端均可以流畅运行。

* 软件要求：本系统基于 python 编写，要求用户设备拥有运行 python  程序及其第三方依赖库的能力。本系统使用数据库，要求用户设备安装相应数据库系统。

### 2.4 第三方依赖

​	本系统开发过程中使用了一定数量的第三方依赖，以下为相应的说明：

* 本系统使用了一定数量的 pyhon 第三方库，以下为对应列表：

  * requests

  * json

  * faker

  * os

  * bs4

  * pymysql

  * sys

  * thefuzz
* 本系统数据库系统为 MySql。



## 数据模型 

### 3.1 数据库设计 

​	为支持本项目爬虫爬取数据存储，并为数据提供维护与检索功能，本项目使用 MySql 及其相应的数据库系统。本项目数据库系统需要支持对数据进行增删查操作，需要支持较高频率的删表、建表与表中数据插入功能。

​	对于面向爬虫的数据存储功能，原先设计为：为每一条爬取信息创建数据库链接和插入操作。在实际应用后发现，以此设计的数据库存储效率较低，经过测试后，查得原因在于频繁的数据库链接操作占用了大部分的操作时间。据此，原有设计更新为：爬取中间过程中得到的数据暂时存储于临时存储空间，待全部数据爬取完成后，再与数据库进行链接并统一进行插入操作。由此，大幅度提升了数据库存储效率。

​	对于面向后端的数据检索功能，设计为：根据单一元素的具体数值进行检索，待数据检索完成后，再统一传输至后端进行下一步的数据处理。

### 3.2 数据库逻辑结构 

​	在本项目中，逻辑设计原本如下 E-R 图所示：

![image-20230711131620317](.assets/image-20230711131620317.png)

​	各关系如下，下划线为键值：

$device\ (\underline{deviceId},deviceStatus,deviceName,deviceType,deviceTime,flooId)$

$floor\ (\underline{floorId},floorName)$

$place\ (\underline{placeId} ,placeName)$

​	共产生三个基本表，在实际查询时使用多表连接查询，各关系符合 $4NF$ 要求，避免了数据冗余、插入异常、更新异常与删除异常。

​	以上设计虽然符合数据库设计要求，但是在实际应用中由于涉及多表查询，会增加 SQL 设计难度且提升查询时间复杂度，并且本表的属性数量较少且总体数据量较少。因此，以追求效率为原则，将原有关系修改如下：

$device\ (\underline{deviceId},deviceStatus,deviceName,deviceType,deviceTime,floorId,floorName,placeId,placeName)$

​	此修改虽然增加了数据冗余，但是在实际应用中，由于不需要对单独的元组进行更新与删除操作，所以基本消除了修改带来的负面影响。同时，由于所有属性放置在同一关系中，避免了在插入过程中复杂的 SQL 设计与查询过程中的多表连接查询，在提升数据库工作效率的同时，也降低了其实现难度，符合本项目的利益。

### 3.3 数据字典

​	为更加清晰明了的说明本项目数据库设计，以下为本数据库的数据字典说明：

* 表清单：$washdata$
* 表关系结构：$washdata\ (\underline{deviceId},deviceStatus,deviceName,deviceType,deviceTime,floorId,floorName,placeId,placeName)$
* 字段说明：
  * $deviceId$：主码，长度为 20 的 CHAR 类型字段
  * $deviceStatus$：非主属性，长度为 20 的 CHAR 类型字段
  * $deviceName$：非主属性，长度为 20 的 CHAR 类型字段
  * $deviceType$：非主属性，长度为 20 的 CHAR 类型字段
  * $deviceTime$：非主属性，长度为 20 的 CHAR 类型字段
  * $floorId$：非主属性，长度为 20 的 CHAR 类型字段
  * $floorName$：非主属性，长度为 20 的 CHAR 类型字段
  * $placeId$：非主属性，长度为 20 的 CHAR 类型字段
  * $placeName$：非主属性，长度为 20 的 CHAR 类型字段
* 字段含义：
  * $deviceId$：机器 id ，每个机器拥有唯一 id
  * $deviceStatus$：机器状态，不同的数值表示机器不同的运行状态，0 表示机器空闲，1 表示机器运行
  * $deviceName$：机器名称，不同机器可以拥有相同的名称
  * $deviceType$：机器类型，不同机器可以拥有相同的类型
  * $deviceTime$：机器时间，表示机器当前剩余的运行时间
  * $floorId$：楼层 id，每个楼层拥有唯一 id
  * $floorName$：楼层名称，不同楼层可以拥有相同名称
  * $placeId$：地点 id，每一个地点有唯一 id
  * $placeName$：地点名称，不同地点可以拥有相同名称，但目前不存在相同名称的不同地点
* 字段约束：
  * $deviceId$：唯一，非空，不可重复
  * $deviceStatus$：非空
  * $deviceName$：非空
  * $deviceType$：非空
  * $deviceTime$：非空
  * $floorId$：唯一，非空
  * $floorName$：非空
  * $placeId$：唯一，非空
  * $placeName$：非空
* 关系描述如上 E-R 图所示。

​	

## 技术栈 

### 4.1 编程语言 

​	本项目基于 python 开发，python 语言包含 80% 以上，另包含约 10% 的 qss 语言与约 10% 的 sql 语言。

### 4.2 框架和库 

​	为实现在 python 语言中较为便利的链接与操作数据库，本项目使用 pymysql 框架以支持相关操作。

​	为实现在 python 语言中较为便利的设计与实现前端界面，本项目使用 pyqt5 框架以支持相关前端程序编写。

​	为实现在 ptthon 语言中较为便利的访问网络资源与解析数据，本项目使用 request 与 json 框架。

### 4.3 开发工具 

​	本项目全程通过 vscode 进行开发。需要安装 conda 对 python 第三方包进行高效管理。需要安装 vscode 中与 python 相关的插件以得到优秀的编程体验。

​	为支持数据库可视化与相关操作，需要安装 vscode 中的 SQLTools、SQLTools MySql 插件，以实现 vscode 对数据库与 sql 的支持。

### 4.4 环境配置

​	需要支持 python 环境，可以直接安装 Anaconda3 以快速实现对 python 环境的配置。安装完成后，需要通过系统高级设置完成 python.exe 的路径配置，以使得 vscode 发现相关的编译器。

​	需要支持 MySql 环境，由官网下载 MySql 后，完成账户初始化，并且在程序中设置对应的数据库用户名与对应密码，即可完成数据库环境配置。	



## 系统模块详细设计 

### 5.1 爬虫模块

​	作为本项目的核心部分，以下是对爬虫模块的详细介绍。

#### 5.1.1 功能描述 

​	本模块负责自动获取用户微信 union Id 对应的 token，自动检查 token 有效性。基于 token 与目标小程序逻辑结构构造 psot 请求，从小程序服务端爬取对应数据，对数据库初步处理后存入数据库。

#### 5.1.2 模块结构 

​	本模块具体结构由以下 UML 图展示：

![image-20230711145844427](.assets/image-20230711145844427.png)

​	本模块共分为 5 个子类，以下对各类功能进行介绍：

* $GetToken$：根据用户 union id 获取对应小程序的 token ，并存储于对应文件中，方便后续对 token 的再次使用与有效性验证。
* $GetJson$：验证 token 有效性，若无效，调用 GetToken 重新获取 token，直到获取有效的 token。根据传入的不同的 header 与 url 自动访问对应网站，并获取服务端返回的 json，返回 json。
* $GetPlaceList$：获取服务地区列表和 id，通过使用 GetJson 和传入对应参数获取对应数据，并将其返回。
* $GetPlaceDetail$：获取对应服务地区的楼层列表和 id，通过使用 GetJson 和传入对应参数获取对应数据，并将其返回。
* $GetFloorDetail$：获取对应服务地区的对应服务楼层的机器列表、 id以及各种数据，通过使用 GetJson 和传入对应参数获取对应数据，并将其返回。

#### 5.1.3 流程图 

​	本模块的具体爬取流程如下流程图所示：

![image-20230711151649726](.assets/image-20230711151649726.png)

#### 5.1.4 输入/输出 

​	以下是该模块中各子模块的输入输出列表：

* $GetToken$：
  * 输入：无
  * 输出：token
* $GetJson$：
  * 输入：对应 url 与 header 
  * 输出：对应 url 返回信息
* $GetPlaceList$：
  * 输入：对应机器类型
  * 输出：对应服务地区列表与 id 列表
* $GetPlaceDetail$：
  * 输入：对应服务地区 id，对应机器类型
  * 输出：对应服务楼层列表与 id 列表
* $GetFloorDetail$：
  * 输入：对应服务楼层 id，对应机器类型
  * 输出：对应机器列表与机器信息列表

### 5.2 数据库模块

​	作为本项目的长期的、大量的数据集合存储系统，以下是对数据库模块的详细介绍。

#### 5.2.1 功能描述 

​	本模块主要用于编写自动完成链接数据、删除数据库中表、创建数据库中表、向表中插入元组、在表中检索元组等功能。作为标准方法为爬虫模块提供数据库存储功能，为后端模块提供数据库检索功能。

#### 5.2.2 模块结构 

​	本模块具体结构由以下 UML 图展示：

![image-20230711153922869](.assets/image-20230711153922869.png)

​	本模块包含一个子模块：用于构建爬虫模块与后端模块对数据库的链接与相关数据库操作。

#### 5.2.3 流程图

​	本模块的具体处理流程如下流程图所示：

![image-20230711155312878](.assets/image-20230711155312878.png)

#### 5.2.4 输入/输出

​	以下是该模块中子模块各方法的输入输出列表：

* $ConnectDB$
  * 输入：数据库用户名称，数据库名称，数据库用户密码
  * 输出：与数据库链接后返回的迭代器
* $DropTable$
  * 输入：删除表名称
  * 输出：删除成功信息或报错信息
* $CreateTable$
  * 输入：创建表名称，创建内容
  * 输出：创建成功信息或报错信息
* $InsertTable$
  * 输入：插入表名称，插入内容
  * 输出：插入成功信息或报错信息
* $SelectFromTable$
  * 输入：选择表名称，选择属性，选择条件
  * 输出：检索结果信息或报错信息

### 5.3 后端模块

​	本模块作为处理前端模块请求与数据模块数据处理的中间模块，以下是对后端模块的详细介绍。

#### 5.3.1 功能描述 

​	本模块主要负责接收前端传入信息，根据前端信息自动构建 SQL 语句，调用数据库模块获取对应数据。得到数据后对其进行评分、排列等处理，将符合前端需求的数据传输回前端。

#### 5.3.2 模块结构 

​	本模块具体结构由以下 UML 图展示：

![image-20230711171525390](.assets/image-20230711171525390.png)

​	本模块包含两个子模块，以下对子模块功能进行详细介绍：

* $Ndoe$：负责记录单个由数据库模块获得的数据。同时记录在另一子模块对数据评估后的分数。
* $DataDeal$：负责接收前端模块需求，对需求进行处理，模糊匹配。与数据库模块建立连接，接收数据库模块返回的数据。对返回数据进行评估与筛选，向前端模块返回处理完成的数据。

#### 5.3.3 流程图

​	本模块的具体处理流程如下流程图所示：

![image-20230711172939873](.assets/image-20230711172939873.png)

#### 5.3.4 输入/输出

​	以下是该模块中各子模块的输入输出列表：

* $DataMix$
  * 输入：设施地址等信息，设施类型
  * 输出：与输入信息对应的设备信息
* $DataText$
  * 输入：无
  * 输出：网页链接列表

### 5.4 前端模块

​	本模块作为用户交互界面，是其余三大模块共同协助输出结果的展示，以下是对该模块的详细介绍。

#### 5.4.1 功能描述 

​	本模块主要构造用户交互界面，为用户提供可视化界面。通过 QS 对用户界面进行初步构建。而后进一步使用 QSS 对用户界面进行美化，优化用户体验。

#### 5.4.2 模块结构 

​	本模块具体结构由以下 UML 图展示：

![image-20230711175744633](.assets/image-20230711175744633.png)

#### 5.4.3 模块效果展示

* 洗衣设备查询界面

![image-20230711180211196](.assets/image-20230711180211196.png)

* 烘干设备查询界面

![image-20230711180228418](.assets/image-20230711180228418.png)

* OA 网站查询界面

![image-20230711180402896](.assets/image-20230711180402896.png)

* 设备搜索效果

![image-20230711180446601](.assets/image-20230711180446601.png)

* 模糊搜索效果

![image-20230711180530080](.assets/image-20230711180530080.png)



## 项目总结

​	本次项目总共用时 4 个学期。虽然第 1、2 学期基本处于打基础阶段，第 3 学期处于实际开发与画饼的叠加态，第 4 个学期在接触感兴趣的爬虫方面后，才实际进行开发，但最终是完成了一个完整的、可实际投入使用项目。

​	在正式开发此项目的过程中，确实遇到了不少的问题。而解决这些问题，虽然花费了大量的时间，但也在这个过程中收获了意料之外的知识。

​	遇到的诸多问题中，作为整个项目核心的爬虫模块出现的问题最多。在学习爬虫的过程中，最先接触的便是以直接解析 html 代码获取相关信息的爬虫。这种爬虫对网页解析程度要求较低，只需要找到目标界面，爬取此界面的 html 代码，解析并将 html 代码转化为标签树的形式，便可以根据需求获取信息了。在前期测试效果的时候，尝试着爬取过几个网页，也得到了不错的效果。但在实际接触小程序后，却发现一个意料之外的问题：无法获取小程序与服务端之间的通信包。造成此问题的原因在于：微信对包含于其中的小程序的通信包进行了隐藏。这一问题在长时间的搜索和询问后，终于在一个不起眼的博客中找到了解决方案：删除微信文件夹中的部分文件。虽然解决的方法出乎意料的简单，但也确确实实的让项目有了关键性的进展。毕竟制作一个爬虫第一步便是先能够获得网站或应用的通信包，得到了通信包，才能够开始对网站结构进行解析，进而构建爬虫。第一步完成了，但接下来却又遇到了问题，小程序与网站不同。对于网站，可以直接通过 edge 的开发者模式获取其中的 html 代码。但对于小程序，便没有办法直接获取 html 了。对于这一问题，最终决定改变爬虫的类型，将获取 html 的爬虫更换为直接通过 api 接口获取对应 json 的爬虫。于是，经过一段时间的学习后，爬虫终于可以通过 api 获得 json，并获取其中的信息了。到此，爬虫开发的第一步便算是完成了。

​	解决了本地的问题，接下来就是解决服务端的问题：验证凭证。对于普通的网站，爬虫往往只需要发送一个 get 请求，然后附上一个正常的 header 就可以通过服务端的验证，获取对应的数据了。但是，作为涉及用户隐私小程序，其服务端验证是较为严格的。从抓包软件中获取正常小程序运行时 post 请求中的信息，一个一个信息的删除后重发请求，最终找到了真正核心的凭证 token。虽然知道了什么是凭证，但是 token 是一串 “乱码” ，这意味着没有办法通过简单的查找规律来获取有效的 token 作为凭证。于是，接下来的问题就变成了破解 token 的构造方法，又或者是找到可以产生 token 的 token。是的，虽然第二个途径看起来像是套娃，但实际上的解决方案正是第二个途径。在梳理了小程序的逻辑结构后，顺着 token 的应用方向逆向搜索，最终发现所有用户的 token 都是在登录小程序时，服务端根据用户微信的 union id 分配的。根据这一发现，通过获取用户微信的 union id，成功实现了自动化获取 token。到此，小程序爬虫遇到的最大问题都被解决了，剩下的任务便是构建小程序的逻辑结构，构建自动化爬取程序。

​	从小程序中拿到了数据，接下来就是将数据存储在数据库之中。由于此开发阶段的同时，学习了数据库相关的知识，在这个过程中没有遇到什么重大的问题。值得一说的便是数据库存储效率的优化和数据库逻辑结构的修改。在一开始，每爬取到一组数据，程序便会向数据库链接，然后插入数据。然而在实际运行中发现这样的存储方法效率极低。在搜索了一定数量的博客后，了解到数据库链接操作耗时较大，存储低效的原因便在于频繁的数据库链接操作。明白了原因，便将存储方法修改为待所有数据爬取完成后，再统一进行存储，结果是让存储效率大幅度提升了。另一方面，在学习了数据库的范式知识后，将数据库的逻辑关系进行了分解，优化了逻辑结构。但是在实际应用中，分解的逻辑关系让查询操作的执行效率下降，并且让相关代码的构建变得复杂。原因是逻辑关系分解后，进行查询时，为了获取足够的信息，需要进行多表连接查询，而这提高了查询所需要的时间。并且由于逻辑关系中属性数量较少，将所有属性放置在同一张表中并不会明显的影响查询效率。所以，基于实际的开发需求，将数据库的逻辑结构恢复到了最初的一张表的状态。

​	接下来便是前后端的处理，由于前期已经对其进行了部分的开发，所以这一部分比较流畅，基本没有问题。主要时间消耗在前端开发框架的选择和前端的构建上。此项目选择用 qt 作为前端开发框架，原因是此框架可以由 python 实现，有利于代码的统一。而且 qt 对前端的构造风格与 java 的 ui 构造风格有一定的相似度，便于上手。而为了让程序用户界面更加美观，使用了 qss 对前端进行美化。qss 与 css 是极其相似的，因此基本没有消耗过多的时间在项目最终的美好上。

​	至此，四大模块开发完成，整个系统构成了一个完整体。在经过了足够的努力后，看到自己的程序可以完成预期的功能，确实带来了足够的满足感。而在满足的同时，自己的专业能力也有所提升，学习到了网络、数据库、后端、前端的知识，还找到了自己感兴趣的方向。总之，本次项目的开发让我收获良多，是一次难得的实践经历。



## 参考资料 

* Python 3 教程https://www.runoob.com/python3/python3-tutorial.html
* [BUG] "h:\code.py" is overriding the stdlib module "code"https://github.com/joedevivo/vscode-circuitpython/issues/106
* anaconda下载及安装https://zhuanlan.zhihu.com/p/459601766
* Anaconda 环境变量手动设置https://blog.csdn.net/weixin_43914658/article/details/108785084
* Win10下Anaconda使用conda activate报错Your shell has not been properly configured to use 'conda activate'https://blog.csdn.net/Pang_Yue__Fairy/article/details/103803645
* [Books to Scrape](http://books.toscrape.com/index.html) 
* python 判断文件或者文件夹是否为空https://blog.csdn.net/Vertira/article/details/122615506
* Python 在创建多进程时抛出RuntimeError错误https://blog.csdn.net/qq_43580193/article/details/105924104
* Python删除字符串中的符号https://blog.csdn.net/O_nice/article/details/124043331
* python unicode 标点范围_不同语言Unicode的编码范围https://blog.csdn.net/weixin_34206263/article/details/112031865
* 如何修复：值的长度与索引的长度不一致https://juejin.cn/post/7116558482429460488
* 微信小程序爬虫https://blog.csdn.net/bullettech2021/article/details/119080790
* 已解决TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。https://blog.csdn.net/yuan2019035055/article/details/128528129
* python爬虫之Beautifulsoup模块用法详解https://zhuanlan.zhihu.com/p/128484144
* 功能强大的python包（七）：BeautifulSouphttps://zhuanlan.zhihu.com/p/394268763
* 前端项目没数据？教你抓取各大网站apihttps://blog.csdn.net/weixin_44823731/article/details/107115047
* https://www.bejson.com/
* PC端微信小程序使用Fiddler进行爬取抓包https://juejin.cn/post/7134952159061213198
* https://www.cnblogs.com/NoId/p/16709499.html
* fiddler无法抓小程序的包https://www.zhihu.com/tardis/zm/art/621416701?source_id=1005
* Python爬虫过程中常见的反扒机制及其应对办法https://blog.csdn.net/a18612039484/article/details/99818307
* Python中requests模块get请求、post请求添加头部、添加Cookiehttps://blog.csdn.net/SDBX_lyp/article/details/115610316
* Python接口自动化-requests模块之post请求https://zhuanlan.zhihu.com/p/140372568
* 接口测试-header头部详解https://zhuanlan.zhihu.com/p/336738395
* 微信开发彻底搞懂unionidhttps://juejin.cn/post/6875521030337757192
* openid会变吗？微信小程序开发中的appid、openid、unionid使用总结https://blog.csdn.net/huluwa10526/article/details/110522033
* MySQL安装到这步出现Current Root Password怎么办？https://blog.csdn.net/qq_36631386/article/details/119577360
* Python进阶知识全篇-MySQL（PyMySQL）https://zhuanlan.zhihu.com/p/139763027
* 使用pymysql库时出现 AttributeError：‘NoneType‘ object has no attribute encoding 的解决方法https://blog.csdn.net/weixin_45961774/article/details/105100910
* 启动MySQL服务的两种方式http://c.biancheng.net/view/7142.html
* 使用Python执行execute插入语句后，执行没有报错，在数据库中没有查询到数据，2种方案解决https://blog.csdn.net/qq_41845402/article/details/127968217
* SQL语句大全https://blog.csdn.net/rankiy/article/details/109245621
* PyQt5实现UI自适应屏幕大小且可缩放https://blog.csdn.net/lavinia_chen007/article/details/118606477
* QFrame Classhttps://doc.qt.io/qt-6/qframe.html
* Qt界面美化QSShttps://blog.csdn.net/qq_29912325/article/details/106873913
* pyqt5如何在同一个窗口下切换不同界面https://blog.csdn.net/weixin_44406200/article/details/105576852
* PyQt5模块代码提示问题https://blog.csdn.net/qq527703883/article/details/116536345
* pyqt使用for循环动态生成按钮等控件，为生成的按钮设置点击等事件https://blog.csdn.net/StrongStrong_/article/details/106766237
* PyQt5无边框后窗口的移动方法https://blog.csdn.net/FanMLei/article/details/79433229
* CSS边框长度控制https://blog.csdn.net/colossalis_c/article/details/71216339
* QT颜色对照表，RGB颜色对照表https://blog.csdn.net/qhy1314520/article/details/119104897
* Pyqt5设置文本超链接https://blog.csdn.net/cftchaoxiaoshu/article/details/122170688